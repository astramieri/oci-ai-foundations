# Prompt Engineering

A **prompt** is the input or initial text provided to the model to elicit a specific response or behavior. So this is something which you write or ask to a language model.

Prompt Engineering is the process of designing and formulating specific instructions or queries to interact with a large language model **effectively**.

The goal of prompt engineering is to ensure that the language model understands the user's intent correctly and provide accurate and relevant responses. The use of prompts with no examples is sometimes referred to as **zero shot** learning. Successful prompts often rely on the practice of **one shot** or **few shot** learning. This refers to the inclusion of one or more examples of the desired behavior of the model, typically by including input and output pairs. Few shot inference involving more than one example is called **in-context learning**.

*In-context learning refers to the capability of generative large language models (LLMs) to learn and perform new tasks without further training or fine-tuning. Instead of modifying the model permanently, users can guide the model's behavior by providing a few examples of the target task through the input prompt. This is particularly useful when direct access to the model is limited, such as when using it through an API or user interface.*

## Best Practices

1. Try writing the prompt input in multiple ways

2. Describe the task with clear and specific instructions

3. Handle edge cases and conditions responses

4. Give examples for completing the task for a desirable outcome